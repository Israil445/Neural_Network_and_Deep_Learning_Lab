{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ccf87f",
   "metadata": {},
   "source": [
    "###  Convert Annotations to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f9a475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] Invalid face count '0--Parade/0_Parade_Parade_0_630.jpg' at line 10424, skipping image: 0 0 0 0 0 0 0 0 0 0\n",
      "[Error] Invalid face count '2--Demonstration/2_Demonstration_Political_Rally_2_414.jpg' at line 86539, skipping image: 0 0 0 0 0 0 0 0 0 0\n",
      "[Error] Invalid face count '39--Ice_Skating/39_Ice_Skating_iceskiing_39_195.jpg' at line 133394, skipping image: 0 0 0 0 0 0 0 0 0 0\n",
      "[Error] Invalid face count '46--Jockey/46_Jockey_Jockey_46_138.jpg' at line 145714, skipping image: 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Convert bounding box to YOLO format\n",
    "def to_yolo_format(img_w, img_h, x, y, w, h):\n",
    "    x_center = (x + w / 2) / img_w\n",
    "    y_center = (y + h / 2) / img_h\n",
    "    width = w / img_w\n",
    "    height = h / img_h\n",
    "    return [0, x_center, y_center, width, height]  # class_id 0 for face\n",
    "\n",
    "# Convert WIDER FACE annotations to YOLO format\n",
    "def convert_widerface_to_yolo(label_path, img_folder, save_img_folder, save_label_folder):\n",
    "    os.makedirs(save_img_folder, exist_ok=True)\n",
    "    os.makedirs(save_label_folder, exist_ok=True)\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]  # remove empty lines\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        img_rel_path = lines[i]\n",
    "        i += 1\n",
    "\n",
    "        if i >= len(lines):\n",
    "            print(f\"[Warning] Missing face count after image: {img_rel_path}\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            face_num = int(lines[i])\n",
    "        except ValueError:\n",
    "            print(f\"[Error] Invalid face count '{lines[i]}' at line {i}, skipping image: {img_rel_path}\")\n",
    "            continue\n",
    "        i += 1\n",
    "\n",
    "        full_img_path = os.path.join(img_folder, img_rel_path)\n",
    "        image = cv2.imread(full_img_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"[Warning] Cannot read image: {full_img_path}\")\n",
    "            i += face_num  # skip all bounding boxes\n",
    "            continue\n",
    "\n",
    "        img_h, img_w = image.shape[:2]\n",
    "\n",
    "        # Save image to new folder\n",
    "        img_filename = os.path.basename(img_rel_path)\n",
    "        save_img_path = os.path.join(save_img_folder, img_filename)\n",
    "        cv2.imwrite(save_img_path, image)\n",
    "\n",
    "        # Create label file\n",
    "        label_filename = os.path.splitext(img_filename)[0] + \".txt\"\n",
    "        label_path = os.path.join(save_label_folder, label_filename)\n",
    "\n",
    "        with open(label_path, 'w') as label_out:\n",
    "            for _ in range(face_num):\n",
    "                if i >= len(lines):\n",
    "                    print(f\"[Warning] Ran out of lines while reading boxes for {img_rel_path}\")\n",
    "                    break\n",
    "                try:\n",
    "                    x, y, w, h, *_ = map(float, lines[i].split())\n",
    "                    i += 1\n",
    "                except ValueError:\n",
    "                    print(f\"[Error] Invalid bbox format at line {i} for image {img_rel_path}\")\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                if w <= 0 or h <= 0:\n",
    "                    continue  # skip invalid boxes\n",
    "\n",
    "                yolo_box = to_yolo_format(img_w, img_h, x, y, w, h)\n",
    "                label_out.write(\" \".join(map(str, yolo_box)) + \"\\n\")\n",
    "\n",
    "# Convert training set\n",
    "convert_widerface_to_yolo(\n",
    "    label_path=\"wider_face_data/wider_face_split/wider_face_train_bbx_gt.txt\",\n",
    "    img_folder=\"wider_face_data/WIDER_train/images\",\n",
    "    save_img_folder=\"wider_face_yolo/train/images\",\n",
    "    save_label_folder=\"wider_face_yolo/train/labels\"\n",
    ")\n",
    "\n",
    "# Convert validation set\n",
    "convert_widerface_to_yolo(\n",
    "    label_path=\"wider_face_data/wider_face_split/wider_face_val_bbx_gt.txt\",\n",
    "    img_folder=\"wider_face_data/WIDER_val/images\",\n",
    "    save_img_folder=\"wider_face_yolo/val/images\",\n",
    "    save_label_folder=\"wider_face_yolo/val/labels\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebbea9",
   "metadata": {},
   "source": [
    "###  Create data.yaml File for YOLOv8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b520a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "path: wider_face_yolo\n",
    "train: train/images\n",
    "val: val/images\n",
    "names:\n",
    "  0: face\n",
    "\"\"\"\n",
    "\n",
    "with open(\"wider_face_yolo/data.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909c836",
   "metadata": {},
   "source": [
    "###  Train YOLOv8 for Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b371e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:12<00:00, 526kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Unfrozen] model.22.cv3.1.2.bias\n",
      "[Unfrozen] model.22.cv3.2.0.conv.weight\n",
      "[Unfrozen] model.22.cv3.2.0.bn.weight\n",
      "[Unfrozen] model.22.cv3.2.0.bn.bias\n",
      "[Unfrozen] model.22.cv3.2.1.conv.weight\n",
      "[Unfrozen] model.22.cv3.2.1.bn.weight\n",
      "[Unfrozen] model.22.cv3.2.1.bn.bias\n",
      "[Unfrozen] model.22.cv3.2.2.weight\n",
      "[Unfrozen] model.22.cv3.2.2.bias\n",
      "[Unfrozen] model.22.dfl.conv.weight\n",
      "Ultralytics 8.3.161 🚀 Python-3.12.3 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7787MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=wider_face_yolo/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8-face, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/yolov8-face, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:03<00:00, 1.63MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1708.9±319.3 MB/s, size: 189.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/train/labels... 12880 images, 4 backgrounds, 0 corrupt: 100%|██████████| 12880/12880 [00:07<00:00, 1776.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/train/images/2_Demonstration_Protesters_2_231.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/train/images/37_Soccer_Soccer_37_851.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/train/images/7_Cheering_Cheering_7_17.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1181.7±352.3 MB/s, size: 186.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/val/labels... 3226 images, 4 backgrounds, 0 corrupt: 100%|██████████| 3226/3226 [00:01<00:00, 1658.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0m/mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/val/images/21_Festival_Festival_21_604.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/wider_face_yolo/val/labels.cache\n",
      "Plotting labels to runs/detect/yolov8-face/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/yolov8-face\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      5.99G      1.954      1.834      1.284        163        640:  69%|██████▉   | 557/805 [01:13<00:28,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      5.99G      1.939      1.779      1.267        160        640:  76%|███████▋  | 614/805 [01:30<00:21,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      5.08G      1.932      1.756      1.259        243        640:  80%|████████  | 644/805 [01:45<00:17,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50       5.2G       1.93       1.75      1.258        164        640:  81%|████████  | 652/805 [02:02<01:18,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      5.22G      1.886       1.64      1.227        281        640: 100%|██████████| 805/805 [02:35<00:00,  5.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:09<00:12,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:22<00:16,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  54%|█████▍    | 55/101 [00:33<00:57,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:49<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.738      0.439      0.492      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      5.33G      1.701      1.133      1.098        572        640:  41%|████▏     | 333/805 [00:39<00:57,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      4.48G      1.707      1.134      1.095        434        640:  49%|████▉     | 397/805 [00:59<00:48,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      5.29G      1.708      1.121      1.089        326        640:  66%|██████▌   | 530/805 [01:32<00:29,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      5.21G      1.699        1.1      1.087        264        640: 100%|██████████| 805/805 [02:12<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.738      0.448      0.502      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      6.39G      1.709      1.062      1.081        358        640:  16%|█▌        | 129/805 [00:14<01:10,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      6.72G      1.699      1.047      1.081        168        640: 100%|██████████| 805/805 [01:44<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:19<00:15,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  54%|█████▍    | 55/101 [00:29<00:56,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:46<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.755      0.415      0.474      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      6.04G      1.695      1.039      1.084        239        640:  24%|██▍       | 195/805 [00:23<01:10,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      6.64G       1.67          1      1.074        155        640: 100%|██████████| 805/805 [01:43<00:00,  7.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:19<00:15,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:37<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.767      0.462      0.527       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      6.88G      1.642     0.9604      1.065        250        640:  95%|█████████▍| 761/805 [01:31<00:04,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      5.74G       1.64     0.9603      1.065        141        640: 100%|██████████| 805/805 [01:50<00:00,  7.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:27<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.783      0.473      0.544       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      6.62G      1.613     0.9362      1.074        215        640:  14%|█▍        | 115/805 [00:13<01:19,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50       5.3G      1.605     0.9325      1.067        399        640:  21%|██        | 171/805 [00:37<01:08,  9.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50       5.3G      1.607     0.9241      1.057        301        640:  70%|███████   | 564/805 [01:35<00:28,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      5.23G      1.606     0.9175      1.054        419        640: 100%|██████████| 805/805 [02:13<00:00,  6.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.78      0.492      0.562       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      4.21G      1.582     0.8904      1.044        357        640:  14%|█▎        | 110/805 [00:12<01:20,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      5.19G      1.584      0.885      1.046        400        640: 100%|██████████| 805/805 [01:51<00:00,  7.25it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:36<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.791      0.498      0.569      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50       6.1G       1.56     0.8742      1.034        594        640:  42%|████▏     | 337/805 [00:40<00:58,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      5.01G      1.563     0.8715      1.037        191        640:  95%|█████████▍| 762/805 [01:45<00:04,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      6.79G      1.565     0.8723      1.037        213        640: 100%|██████████| 805/805 [01:59<00:00,  6.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.794      0.512      0.583      0.306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      6.38G       1.54     0.8441      1.034        317        640:  41%|████      | 327/805 [00:39<00:57,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      6.38G      1.547     0.8503      1.036        217        640: 100%|██████████| 805/805 [01:47<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.804      0.516      0.587      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      6.79G      1.541     0.8366      1.031        211        640:  40%|████      | 323/805 [00:38<00:54,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50       5.1G      1.532     0.8298      1.029        573        640:  59%|█████▉    | 476/805 [01:05<00:40,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50       5.4G      1.528     0.8313      1.029        281        640: 100%|██████████| 805/805 [02:01<00:00,  6.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.812      0.512      0.595      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      5.96G      1.534     0.8326      1.032        285        640:  40%|████      | 326/805 [00:38<00:56,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      6.93G      1.528     0.8307      1.027        225        640:  85%|████████▍ | 684/805 [01:34<00:13,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      6.74G      1.526     0.8287      1.028        319        640: 100%|██████████| 805/805 [01:57<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.81      0.528      0.599      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      5.42G      1.492     0.8146      1.024        109        640:  45%|████▍     | 362/805 [00:42<00:49,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      6.87G      1.508     0.8229      1.025        442        640:  66%|██████▌   | 528/805 [01:14<00:35,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      6.71G       1.51      0.821      1.025        166        640: 100%|██████████| 805/805 [01:59<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.808      0.529      0.601      0.319\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      5.61G      1.507      0.809      1.025        308        640:  40%|████      | 326/805 [00:38<00:54,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      6.74G      1.506     0.8105      1.022        166        640: 100%|██████████| 805/805 [01:48<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.815      0.528      0.604      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      5.65G      1.503     0.8016      1.017        255        640:  76%|███████▌  | 613/805 [01:12<00:21,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      5.65G      1.501     0.8005      1.017        428        640:  80%|████████  | 645/805 [01:25<00:18,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      5.65G      1.501     0.8016      1.018        458        640: 100%|██████████| 805/805 [01:52<00:00,  7.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.811      0.534      0.606      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      6.66G      1.493     0.7896      1.009        404        640:  30%|███       | 242/805 [00:29<01:06,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      5.27G      1.498     0.7898      1.009        297        640:  33%|███▎      | 266/805 [00:48<01:04,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      5.27G      1.496     0.7924      1.014        699        640: 100%|██████████| 805/805 [02:04<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.828       0.54      0.618      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      5.93G      1.469     0.7746      1.013        377        640:  21%|██▏       | 172/805 [00:20<01:18,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      6.74G      1.481     0.7835      1.013        271        640: 100%|██████████| 805/805 [01:48<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.83      0.541      0.622      0.334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      5.96G       1.49     0.7865      1.014        160        640: 100%|██████████| 805/805 [01:35<00:00,  8.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.818      0.546      0.619      0.329\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      6.91G      1.475      0.773      1.009        143        640:  63%|██████▎   | 506/805 [01:01<00:36,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      5.57G      1.475     0.7735      1.009        171        640:  65%|██████▍   | 522/805 [01:19<00:41,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      5.57G      1.475     0.7722      1.013        700        640:  98%|█████████▊| 790/805 [02:03<00:01,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      5.57G      1.477     0.7734      1.013        182        640: 100%|██████████| 805/805 [02:17<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.823      0.545      0.626      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50       6.2G      1.423     0.7243     0.9987        261        640:   2%|▏         | 17/805 [00:02<01:32,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      5.44G      1.441     0.7587      1.008        179        640:  18%|█▊        | 148/805 [00:30<01:14,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      6.93G      1.468     0.7709       1.01        304        640: 100%|██████████| 805/805 [02:01<00:00,  6.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.823      0.555      0.633       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      4.64G      1.511     0.7831      1.004        398        640:  12%|█▏        | 94/805 [00:10<01:19,  8.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      6.86G      1.465       0.76      1.004        384        640:  96%|█████████▋| 776/805 [01:49<00:03,  7.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      5.15G      1.466     0.7611      1.004        182        640: 100%|██████████| 805/805 [02:03<00:00,  6.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.827      0.552      0.629      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      6.67G      1.472     0.7663      1.016        317        640:   9%|▊         | 70/805 [00:08<01:19,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G      1.484     0.7663      1.011        169        640:  11%|█▏        | 92/805 [00:22<01:30,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G       1.45     0.7556      1.007        126        640:  57%|█████▋    | 461/805 [01:14<00:37,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.52G      1.451     0.7565      1.007        170        640:  60%|██████    | 486/805 [01:24<00:35,  9.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.52G      1.451     0.7569      1.007        241        640:  63%|██████▎   | 507/805 [01:36<00:35,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.52G      1.451     0.7582      1.008        498        640:  71%|███████   | 571/805 [01:56<00:26,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G      1.453     0.7599      1.008        326        640:  74%|███████▍  | 594/805 [02:09<00:25,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G      1.454     0.7602      1.008        379        640:  75%|███████▍  | 600/805 [02:18<01:50,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G      1.455     0.7607      1.008        278        640:  77%|███████▋  | 616/805 [02:29<00:23,  7.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.53G      1.458     0.7612      1.006        179        640: 100%|██████████| 805/805 [03:03<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:05<00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.826      0.554       0.63       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      6.79G      1.473     0.7633      1.003        712        640:  52%|█████▏    | 419/805 [00:48<00:46,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      6.79G      1.457     0.7552      1.002        170        640: 100%|██████████| 805/805 [01:42<00:00,  7.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:05<00:11,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.823      0.557      0.632      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      6.16G      1.448     0.7465      1.004        620        640: 100%|██████████| 805/805 [01:36<00:00,  8.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:36<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.826      0.556      0.636      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      4.63G      1.431     0.7304     0.9954        405        640:  52%|█████▏    | 422/805 [00:49<00:47,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      5.44G      1.434     0.7314     0.9952        158        640:  54%|█████▍    | 434/805 [01:08<01:34,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      5.44G      1.443     0.7417     0.9979        206        640: 100%|██████████| 805/805 [02:08<00:00,  6.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.832      0.556      0.637      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50       4.9G      1.479     0.7544     0.9907        294        640:  16%|█▌        | 128/805 [00:15<01:19,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      6.74G      1.478     0.7549     0.9907        449        640:  18%|█▊        | 144/805 [00:32<01:38,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      4.93G      1.471     0.7521     0.9902        171        640:  23%|██▎       | 184/805 [00:49<01:09,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      5.26G      1.453     0.7472     0.9972        214        640: 100%|██████████| 805/805 [02:20<00:00,  5.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.831      0.559       0.64      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      6.46G      1.443     0.7392     0.9997        238        640:  92%|█████████▏| 742/805 [01:29<00:07,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      4.71G      1.444     0.7396     0.9999        263        640:  96%|█████████▌| 774/805 [01:44<00:03,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      4.71G      1.443     0.7385     0.9994        391        640: 100%|██████████| 805/805 [01:59<00:00,  6.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.833      0.558      0.637      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      5.11G      1.452     0.7409     0.9975        232        640:  39%|███▉      | 312/805 [00:37<00:57,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      4.54G      1.451     0.7372     0.9965        130        640:  44%|████▎     | 352/805 [00:54<00:52,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      4.62G       1.45     0.7365     0.9962        423        640:  46%|████▌     | 368/805 [01:09<00:57,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      4.62G      1.438     0.7325     0.9948        229        640:  94%|█████████▍| 757/805 [02:08<00:05,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      6.43G      1.438     0.7321     0.9955        221        640: 100%|██████████| 805/805 [02:24<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:05<00:11,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.833      0.561       0.64      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.92G      1.415     0.7345     0.9911        177        640:   1%|          | 8/805 [00:01<01:34,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.416     0.7235     0.9999        151        640:  45%|████▌     | 366/805 [00:58<00:59,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.418     0.7241     0.9998        122        640:  48%|████▊     | 390/805 [01:16<00:46,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.427     0.7292     0.9984        185        640:  69%|██████▊   | 553/805 [01:46<00:28,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.428     0.7285     0.9981        151        640:  74%|███████▎  | 593/805 [02:02<00:25,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.429     0.7277     0.9973        317        640:  94%|█████████▍| 758/805 [02:30<00:05,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.429     0.7278     0.9971        289        640:  96%|█████████▌| 771/805 [02:44<00:06,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.429     0.7271     0.9964        195        640:  98%|█████████▊| 790/805 [02:54<00:01,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.44G      1.428     0.7266     0.9961        299        640: 100%|██████████| 805/805 [03:04<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.834      0.561      0.643      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      6.57G      1.434      0.732     0.9917        153        640:  44%|████▍     | 356/805 [00:41<00:47,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      6.82G      1.432     0.7292     0.9917        311        640: 100%|██████████| 805/805 [01:49<00:00,  7.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.833      0.566      0.646       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      4.99G      1.401      0.705     0.9884        489        640:  37%|███▋      | 294/805 [00:34<01:04,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      6.83G      1.426     0.7218     0.9924        453        640: 100%|██████████| 805/805 [01:48<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.833      0.568      0.647      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      5.91G      1.426     0.7234     0.9944        377        640:  28%|██▊       | 223/805 [00:27<01:08,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      6.53G      1.423     0.7191     0.9914        644        640:  93%|█████████▎| 749/805 [01:44<00:07,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      6.82G      1.423     0.7193     0.9913        172        640:  94%|█████████▍| 757/805 [02:02<00:26,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      6.49G      1.422     0.7184     0.9905        236        640:  99%|█████████▉| 797/805 [02:19<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      4.75G      1.423     0.7184     0.9906        802        640: 100%|██████████| 805/805 [02:30<00:00,  5.34it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836      0.566      0.646      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      6.51G      1.418     0.7157     0.9881        266        640:  45%|████▌     | 363/805 [00:43<00:49,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      5.34G      1.412      0.711     0.9869        282        640:  72%|███████▏  | 579/805 [01:26<00:25,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      6.52G       1.41     0.7095     0.9858        375        640: 100%|██████████| 805/805 [02:03<00:00,  6.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.833      0.571       0.65      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      5.54G      1.399     0.6999      0.988        254        640:  77%|███████▋  | 617/805 [01:13<00:22,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      6.22G      1.401     0.7021     0.9895        376        640: 100%|██████████| 805/805 [01:51<00:00,  7.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.832      0.573      0.652      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.82G      1.401     0.7051     0.9819        215        640:  20%|█▉        | 157/805 [00:18<01:13,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      4.62G      1.403     0.7033     0.9854        398        640:  22%|██▏       | 181/805 [00:34<01:18,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.14G      1.402     0.7042      0.986        208        640:  33%|███▎      | 269/805 [01:00<01:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50       6.8G      1.408     0.7065     0.9869        280        640:  70%|██████▉   | 560/805 [01:43<00:27,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.07G      1.409     0.7069     0.9874        311        640:  73%|███████▎  | 584/805 [01:55<00:25,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.07G      1.409      0.707     0.9869         89        640:  78%|███████▊  | 624/805 [02:09<00:21,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.68G      1.418     0.7117     0.9879        167        640: 100%|██████████| 805/805 [02:43<00:00,  4.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.838      0.573      0.653      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      4.05G      1.477     0.7384     0.9934        400        640:   2%|▏         | 13/805 [00:01<01:39,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      6.05G      1.403     0.7026     0.9865        524        640:  52%|█████▏    | 420/805 [01:02<00:50,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      4.79G      1.392     0.6973     0.9857        244        640: 100%|██████████| 805/805 [02:00<00:00,  6.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.837      0.572      0.654      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.34G      1.402     0.6981     0.9865        100        640:  65%|██████▍   | 520/805 [01:02<00:34,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      4.81G      1.404        0.7     0.9869        185        640:  68%|██████▊   | 544/805 [01:18<00:30,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.03G      1.406        0.7     0.9865        413        640:  83%|████████▎ | 668/805 [01:48<00:17,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.03G      1.407     0.7003     0.9862        146        640:  84%|████████▍ | 676/805 [02:00<00:52,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.32G      1.407     0.7006     0.9862        131        640:  86%|████████▌ | 692/805 [02:19<00:15,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.32G      1.401     0.6982     0.9858        360        640: 100%|██████████| 805/805 [02:42<00:00,  4.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836      0.573      0.652      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      5.51G      1.397     0.6955     0.9831        237        640:  91%|█████████ | 733/805 [01:28<00:09,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50       5.8G      1.395     0.6941     0.9828        247        640: 100%|█████████▉| 802/805 [01:47<00:00,  9.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      4.88G      1.396     0.6943     0.9828        211        640: 100%|██████████| 805/805 [01:58<00:00,  6.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.837      0.575      0.655      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      5.44G      1.381     0.6867     0.9831        261        640:  35%|███▍      | 279/805 [00:33<00:59,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      5.66G       1.39     0.6924     0.9795        282        640:  96%|█████████▌| 773/805 [01:51<00:03,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      5.66G      1.393     0.6942     0.9801        445        640: 100%|██████████| 805/805 [02:07<00:00,  6.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836      0.575      0.655      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      6.47G      1.384     0.6867     0.9795        342        640:  92%|█████████▏| 740/805 [01:27<00:07,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      5.29G      1.388     0.6883     0.9788        386        640: 100%|██████████| 805/805 [01:52<00:00,  7.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836      0.577      0.656      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      5.29G      1.376     0.6717     0.9769        338        640:  47%|████▋     | 379/805 [00:44<00:49,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      5.33G      1.384     0.6825     0.9784        117        640:  88%|████████▊ | 710/805 [01:41<00:11,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      5.18G      1.382     0.6806     0.9788        327        640: 100%|██████████| 805/805 [02:01<00:00,  6.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836       0.58      0.659      0.359\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      5.91G      1.362     0.6608     0.9812        182        640:  53%|█████▎    | 424/805 [00:48<00:42,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      6.91G      1.366     0.6622     0.9849        194        640:  87%|████████▋ | 698/805 [01:31<00:12,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      5.76G      1.365     0.6602     0.9852        431        640: 100%|██████████| 805/805 [02:00<00:00,  6.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.835      0.577      0.656      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      6.14G      1.356     0.6572     0.9816         96        640:  57%|█████▋    | 462/805 [00:52<00:39,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      5.09G      1.357     0.6537     0.9819        130        640: 100%|█████████▉| 802/805 [01:42<00:00,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      5.19G      1.358     0.6543     0.9819         85        640: 100%|██████████| 805/805 [01:54<00:00,  7.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.841      0.574      0.656      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      5.88G      1.346      0.643     0.9828         33        640:  51%|█████     | 410/805 [00:48<00:43,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      4.96G      1.347     0.6443     0.9824        218        640:  67%|██████▋   | 539/805 [01:13<00:30,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      6.67G      1.344     0.6431     0.9829        165        640:  84%|████████▎ | 673/805 [01:45<00:14,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      6.67G      1.349     0.6454     0.9815        174        640: 100%|██████████| 805/805 [02:16<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:15,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.836      0.577      0.656      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      5.52G      1.349     0.6441     0.9796         55        640:  63%|██████▎   | 507/805 [00:58<00:32,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      5.52G      1.349     0.6445     0.9785        125        640:  76%|███████▌  | 611/805 [01:20<00:24,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      5.78G      1.349     0.6444     0.9783         86        640:  80%|███████▉  | 641/805 [01:38<00:17,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      5.78G      1.345     0.6438     0.9787        135        640: 100%|██████████| 805/805 [02:05<00:00,  6.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.84      0.577      0.656      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.57G      1.328     0.6334     0.9785        198        640:  31%|███       | 248/805 [00:27<01:06,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.24G      1.345     0.6427     0.9774        220        640:  51%|█████     | 411/805 [01:03<00:44,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.24G      1.344     0.6421     0.9783        162        640:  58%|█████▊    | 463/805 [01:17<00:37,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.36G      1.345     0.6425     0.9779        499        640:  71%|███████   | 568/805 [01:46<00:25,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.36G      1.341     0.6389     0.9779        106        640: 100%|██████████| 805/805 [02:24<00:00,  5.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.84      0.577      0.657      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      4.24G      1.398     0.6401     0.9419        137        640:   1%|          | 10/805 [00:01<01:37,  8.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      5.26G      1.337     0.6362     0.9756        738        640:  84%|████████▍ | 675/805 [01:33<00:17,  7.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      5.35G      1.339     0.6368     0.9757        121        640:  85%|████████▍ | 684/805 [01:52<00:51,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      5.35G      1.339     0.6362     0.9755         91        640: 100%|██████████| 805/805 [02:16<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.837      0.579      0.658       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      6.33G      1.332     0.6301     0.9742         79        640:  49%|████▊     | 392/805 [00:44<00:46,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      5.68G      1.335     0.6308     0.9739        466        640:  67%|██████▋   | 540/805 [01:18<00:31,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      5.68G      1.332     0.6275     0.9729         86        640: 100%|█████████▉| 802/805 [02:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      5.68G      1.333     0.6279     0.9729        292        640: 100%|██████████| 805/805 [02:09<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 51/101 [00:18<00:14,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:35<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696       0.84      0.579      0.659       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      5.52G      1.301     0.6175     0.9736         66        640:  15%|█▌        | 122/805 [00:13<01:14,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      6.08G      1.318     0.6191     0.9722        582        640:  92%|█████████▏| 737/805 [01:40<00:08,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      5.12G       1.32     0.6204     0.9719         72        640: 100%|██████████| 805/805 [01:59<00:00,  6.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.842      0.577      0.659      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      6.38G      1.326     0.6236     0.9685        374        640:  39%|███▉      | 312/805 [00:35<01:01,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      5.26G      1.321     0.6202     0.9668        179        640:  50%|█████     | 406/805 [00:57<00:45,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      6.89G      1.321     0.6192     0.9669        317        640: 100%|██████████| 805/805 [01:54<00:00,  7.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:25<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.839      0.578      0.659       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      6.53G      1.315     0.6144     0.9674         95        640:  71%|███████   | 570/805 [01:04<00:26,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50       5.3G      1.318     0.6157      0.967        198        640:  98%|█████████▊| 785/805 [01:45<00:02,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      5.33G      1.319     0.6158      0.967        168        640: 100%|██████████| 805/805 [02:05<00:00,  6.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  41%|████      | 41/101 [00:06<00:11,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:26<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.841      0.579       0.66      0.361\n",
      "\n",
      "50 epochs completed in 2.161 hours.\n",
      "Optimizer stripped from runs/detect/yolov8-face/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/yolov8-face/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/yolov8-face/weights/best.pt...\n",
      "Ultralytics 8.3.161 🚀 Python-3.12.3 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7787MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [00:13<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3226      39696      0.842      0.577      0.659      0.361\n",
      "Speed: 0.1ms preprocess, 1.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/yolov8-face\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x78da807936e0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
       "            0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
       "            0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
       "            0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
       "            0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,\n",
       "            0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99948,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99936,     0.99921,     0.99921,     0.99921,     0.99909,\n",
       "            0.99909,     0.99909,     0.99909,     0.99909,     0.99909,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,\n",
       "            0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,\n",
       "            0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99905,     0.99896,     0.99896,     0.99896,     0.99896,     0.99896,     0.99885,     0.99864,     0.99864,     0.99864,     0.99854,     0.99854,     0.99854,     0.99844,     0.99837,     0.99837,     0.99837,     0.99837,\n",
       "            0.99837,     0.99837,     0.99828,     0.99828,     0.99809,     0.99809,     0.99809,     0.99801,     0.99801,     0.99801,     0.99801,     0.99794,     0.99794,     0.99794,     0.99794,     0.99793,     0.99793,     0.99793,     0.99793,     0.99793,     0.99793,     0.99793,     0.99793,\n",
       "            0.99793,     0.99793,     0.99788,     0.99788,     0.99788,     0.99788,     0.99788,     0.99788,     0.99784,     0.99784,     0.99784,     0.99784,     0.99784,     0.99784,     0.99784,     0.99767,     0.99767,     0.99759,     0.99751,     0.99743,     0.99743,     0.99736,     0.99736,\n",
       "            0.99711,     0.99711,     0.99702,     0.99695,     0.99679,     0.99672,     0.99672,     0.99665,     0.99665,     0.99658,     0.99651,     0.99651,     0.99648,     0.99648,     0.99648,     0.99648,      0.9964,     0.99634,     0.99634,     0.99627,     0.99625,     0.99625,     0.99625,\n",
       "            0.99625,     0.99625,     0.99617,     0.99594,     0.99587,     0.99572,     0.99552,     0.99552,     0.99552,     0.99537,     0.99532,     0.99532,     0.99517,     0.99501,     0.99501,     0.99501,     0.99501,     0.99501,     0.99483,     0.99483,     0.99483,     0.99477,     0.99463,\n",
       "            0.99457,     0.99451,     0.99445,      0.9944,      0.9944,     0.99434,     0.99421,     0.99409,     0.99409,     0.99389,     0.99384,      0.9938,      0.9938,     0.99375,     0.99368,     0.99341,     0.99334,      0.9933,     0.99319,     0.99319,     0.99306,     0.99288,     0.99283,\n",
       "            0.99283,     0.99265,     0.99259,     0.99218,     0.99215,     0.99181,     0.99164,     0.99164,     0.99138,     0.99098,     0.99081,     0.99064,     0.99057,     0.99053,     0.99035,     0.99019,     0.98999,     0.98989,     0.98978,     0.98961,     0.98922,     0.98902,     0.98902,\n",
       "            0.98878,     0.98855,     0.98844,     0.98827,     0.98811,       0.988,     0.98758,     0.98757,     0.98757,     0.98742,     0.98706,     0.98677,     0.98654,     0.98635,      0.9863,     0.98607,     0.98598,     0.98585,     0.98568,      0.9854,     0.98513,     0.98494,     0.98494,\n",
       "             0.9846,     0.98447,     0.98407,     0.98398,     0.98384,     0.98363,     0.98342,     0.98315,     0.98289,     0.98251,     0.98232,      0.9823,     0.98224,     0.98221,     0.98209,     0.98199,      0.9818,     0.98154,     0.98128,      0.9811,     0.98079,     0.98072,     0.98058,\n",
       "            0.98006,     0.97981,     0.97929,     0.97921,     0.97896,     0.97838,     0.97804,     0.97762,       0.977,     0.97668,     0.97658,     0.97637,     0.97631,     0.97602,     0.97563,     0.97501,     0.97451,     0.97429,     0.97403,     0.97385,     0.97353,     0.97272,     0.97245,\n",
       "            0.97191,      0.9717,     0.97122,     0.97069,     0.97039,      0.9699,     0.96945,     0.96897,     0.96847,      0.9681,     0.96785,      0.9675,     0.96684,     0.96623,      0.9658,     0.96554,     0.96495,     0.96461,     0.96396,     0.96358,     0.96289,      0.9625,     0.96233,\n",
       "              0.962,     0.96123,     0.96081,     0.96048,     0.95987,     0.95921,      0.9588,     0.95829,     0.95787,     0.95727,     0.95682,     0.95651,     0.95626,     0.95581,     0.95537,     0.95474,     0.95429,     0.95376,     0.95328,     0.95275,     0.95223,     0.95134,     0.95101,\n",
       "            0.95067,      0.9503,     0.94937,     0.94858,     0.94802,     0.94734,     0.94679,     0.94602,     0.94549,      0.9445,      0.9436,      0.9433,     0.94236,      0.9422,     0.94144,      0.9409,     0.94012,     0.93952,     0.93884,     0.93817,     0.93741,     0.93689,     0.93637,\n",
       "            0.93564,      0.9349,     0.93415,     0.93321,     0.93254,     0.93181,     0.93095,     0.92993,     0.92846,     0.92766,     0.92682,     0.92585,     0.92521,     0.92418,     0.92311,     0.92222,     0.92154,     0.92082,     0.91958,     0.91826,     0.91664,     0.91561,     0.91457,\n",
       "             0.9129,     0.91216,     0.91062,     0.90953,     0.90848,     0.90711,     0.90579,     0.90499,     0.90389,     0.90267,     0.90113,     0.89997,      0.8983,     0.89715,     0.89577,     0.89423,     0.89215,     0.89065,     0.88918,     0.88733,     0.88619,       0.885,      0.8838,\n",
       "            0.88218,     0.88132,     0.88028,     0.87939,      0.8779,     0.87683,     0.87513,     0.87374,     0.87243,     0.86993,     0.86875,     0.86731,     0.86613,     0.86451,     0.86265,     0.86032,     0.85899,     0.85732,     0.85505,     0.85282,     0.85087,     0.84887,     0.84694,\n",
       "            0.84508,     0.84306,     0.84109,     0.83955,     0.83751,     0.83541,      0.8327,        0.83,     0.82745,     0.82499,     0.82264,     0.82054,     0.81848,     0.81648,     0.81412,     0.81122,     0.80865,     0.80584,     0.80305,     0.80134,     0.79898,     0.79609,     0.79225,\n",
       "            0.79022,     0.78713,     0.78392,     0.78125,     0.77759,     0.77531,     0.77285,      0.7692,     0.76559,     0.76254,     0.75934,     0.75672,     0.75293,     0.74961,     0.74642,     0.74304,     0.73992,     0.73673,     0.73435,     0.73113,     0.72757,     0.72348,     0.72146,\n",
       "            0.71806,     0.71423,     0.70987,     0.70648,      0.7034,     0.69988,     0.69605,     0.69075,     0.68682,     0.68226,     0.67966,     0.67561,     0.67157,     0.66607,     0.66328,     0.65866,     0.65365,      0.6491,     0.64611,     0.64013,      0.6344,     0.62885,     0.62476,\n",
       "            0.61999,     0.61398,     0.60997,     0.60582,     0.60106,       0.595,     0.59021,     0.58436,     0.57765,     0.57192,     0.56751,     0.56058,     0.55489,     0.54859,     0.54151,     0.53606,     0.52934,     0.52364,     0.51742,     0.51135,     0.50637,     0.50014,     0.49392,\n",
       "            0.48924,      0.4811,     0.47405,     0.46669,     0.45859,      0.4536,      0.4493,     0.44239,      0.4373,     0.43132,     0.42508,     0.42069,      0.4138,     0.40654,     0.39929,     0.39043,      0.3844,     0.37815,     0.36849,     0.36216,     0.35383,     0.34755,     0.33745,\n",
       "            0.32686,     0.31962,     0.31407,     0.30598,     0.29803,     0.29138,     0.28418,     0.27634,     0.26577,     0.25857,     0.24835,     0.23783,      0.2297,     0.22032,     0.21021,     0.20082,     0.19064,     0.18428,     0.17276,     0.16107,     0.15084,     0.14044,     0.12964,\n",
       "            0.11515,     0.11475,     0.11434,     0.11394,     0.11354,     0.11314,     0.11273,     0.11233,     0.11193,     0.11153,     0.11112,     0.11072,     0.11032,     0.10992,     0.10951,     0.10911,     0.10871,     0.10831,      0.1079,      0.1075,      0.1071,     0.10669,     0.10629,\n",
       "            0.10589,     0.10549,     0.10508,     0.10468,     0.10428,     0.10388,     0.10347,     0.10307,     0.10267,     0.10227,     0.10186,     0.10146,     0.10106,     0.10066,     0.10025,     0.09985,    0.099447,    0.099045,    0.098642,    0.098239,    0.097837,    0.097434,    0.097032,\n",
       "           0.096629,    0.096226,    0.095824,    0.095421,    0.095019,    0.094616,    0.094213,    0.093811,    0.093408,    0.093005,    0.092603,      0.0922,    0.091798,    0.091395,    0.090992,     0.09059,    0.090187,    0.089784,    0.089382,    0.088979,    0.088577,    0.088174,    0.087771,\n",
       "           0.087369,    0.086966,    0.086563,    0.086161,    0.085758,    0.085356,    0.084953,     0.08455,    0.084148,    0.083745,    0.083343,     0.08294,    0.082537,    0.082135,    0.081732,    0.081329,    0.080927,    0.080524,    0.080122,    0.079719,    0.079316,    0.078914,    0.078511,\n",
       "           0.078108,    0.077706,    0.077303,    0.076901,    0.076498,    0.076095,    0.075693,     0.07529,    0.074887,    0.074485,    0.074082,     0.07368,    0.073277,    0.072874,    0.072472,    0.072069,    0.071667,    0.071264,    0.070861,    0.070459,    0.070056,    0.069653,    0.069251,\n",
       "           0.068848,    0.068446,    0.068043,     0.06764,    0.067238,    0.066835,    0.066432,     0.06603,    0.065627,    0.065225,    0.064822,    0.064419,    0.064017,    0.063614,    0.063211,    0.062809,    0.062406,    0.062004,    0.061601,    0.061198,    0.060796,    0.060393,    0.059991,\n",
       "           0.059588,    0.059185,    0.058783,     0.05838,    0.057977,    0.057575,    0.057172,     0.05677,    0.056367,    0.055964,    0.055562,    0.055159,    0.054756,    0.054354,    0.053951,    0.053549,    0.053146,    0.052743,    0.052341,    0.051938,    0.051535,    0.051133,     0.05073,\n",
       "           0.050328,    0.049925,    0.049522,     0.04912,    0.048717,    0.048315,    0.047912,    0.047509,    0.047107,    0.046704,    0.046301,    0.045899,    0.045496,    0.045094,    0.044691,    0.044288,    0.043886,    0.043483,     0.04308,    0.042678,    0.042275,    0.041873,     0.04147,\n",
       "           0.041067,    0.040665,    0.040262,    0.039859,    0.039457,    0.039054,    0.038652,    0.038249,    0.037846,    0.037444,    0.037041,    0.036638,    0.036236,    0.035833,    0.035431,    0.035028,    0.034625,    0.034223,     0.03382,    0.033418,    0.033015,    0.032612,     0.03221,\n",
       "           0.031807,    0.031404,    0.031002,    0.030599,    0.030197,    0.029794,    0.029391,    0.028989,    0.028586,    0.028183,    0.027781,    0.027378,    0.026976,    0.026573,     0.02617,    0.025768,    0.025365,    0.024962,     0.02456,    0.024157,    0.023755,    0.023352,    0.022949,\n",
       "           0.022547,    0.022144,    0.021742,    0.021339,    0.020936,    0.020534,    0.020131,    0.019728,    0.019326,    0.018923,    0.018521,    0.018118,    0.017715,    0.017313,     0.01691,    0.016507,    0.016105,    0.015702,      0.0153,    0.014897,    0.014494,    0.014092,    0.013689,\n",
       "           0.013286,    0.012884,    0.012481,    0.012079,    0.011676,    0.011273,    0.010871,    0.010468,    0.010066,   0.0096629,   0.0092603,   0.0088577,    0.008455,   0.0080524,   0.0076498,   0.0072472,   0.0068446,   0.0064419,   0.0060393,   0.0056367,   0.0052341,   0.0048315,   0.0044288,\n",
       "          0.0040262,   0.0036236,    0.003221,   0.0028183,   0.0024157,   0.0020131,   0.0016105,   0.0012079,  0.00080524,  0.00040262,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19831,     0.19831,     0.24135,     0.27062,     0.29383,     0.31302,     0.32973,     0.34359,     0.35676,     0.36862,     0.37954,     0.38903,     0.39832,     0.40658,     0.41493,     0.42263,     0.42996,     0.43694,     0.44353,     0.45031,     0.45644,     0.46207,     0.46754,\n",
       "            0.47308,     0.47816,     0.48312,     0.48786,     0.49212,     0.49623,     0.50053,     0.50487,     0.50904,     0.51264,     0.51634,     0.51985,     0.52348,     0.52689,     0.52992,     0.53331,     0.53582,     0.53905,     0.54196,     0.54457,     0.54799,     0.55057,     0.55346,\n",
       "            0.55615,     0.55848,     0.56104,     0.56379,     0.56576,      0.5679,      0.5704,     0.57238,     0.57471,     0.57682,     0.57881,      0.5806,     0.58257,     0.58498,     0.58669,     0.58865,     0.59047,     0.59275,     0.59431,     0.59588,     0.59756,     0.59911,     0.60149,\n",
       "            0.60285,     0.60457,      0.6063,     0.60743,     0.60897,     0.61032,      0.6118,     0.61296,     0.61454,     0.61617,      0.6174,     0.61901,     0.62017,     0.62122,     0.62294,     0.62406,     0.62565,     0.62678,     0.62782,      0.6288,     0.62985,     0.63128,     0.63236,\n",
       "            0.63337,     0.63439,     0.63537,      0.6363,     0.63729,     0.63836,     0.63921,      0.6399,     0.64103,     0.64201,     0.64302,     0.64371,     0.64425,     0.64537,     0.64623,     0.64708,     0.64786,     0.64869,     0.64958,     0.64994,     0.65074,     0.65141,     0.65245,\n",
       "            0.65294,     0.65369,     0.65424,     0.65499,     0.65533,     0.65614,     0.65668,      0.6574,     0.65808,     0.65854,     0.65967,     0.66003,     0.66061,     0.66124,     0.66164,     0.66211,     0.66267,     0.66302,     0.66339,     0.66387,     0.66432,     0.66508,     0.66555,\n",
       "            0.66594,     0.66635,     0.66664,     0.66714,     0.66743,     0.66752,     0.66783,     0.66867,     0.66901,     0.66955,     0.66978,      0.6701,     0.67054,     0.67075,     0.67111,     0.67137,     0.67171,     0.67193,     0.67223,     0.67276,     0.67285,     0.67314,     0.67346,\n",
       "            0.67369,      0.6742,     0.67445,     0.67497,     0.67525,      0.6755,     0.67559,     0.67582,     0.67616,     0.67656,     0.67685,     0.67701,     0.67736,     0.67753,     0.67777,     0.67818,     0.67841,     0.67859,     0.67876,     0.67895,     0.67891,     0.67913,     0.67933,\n",
       "            0.67969,     0.67984,     0.67999,      0.6802,     0.68021,     0.68056,     0.68082,     0.68099,     0.68117,     0.68127,     0.68123,     0.68151,     0.68191,     0.68204,     0.68239,     0.68244,     0.68255,     0.68256,     0.68267,     0.68269,     0.68267,     0.68263,     0.68278,\n",
       "            0.68317,     0.68326,     0.68325,     0.68347,     0.68346,     0.68376,     0.68389,     0.68385,     0.68384,     0.68406,     0.68401,     0.68401,     0.68406,     0.68403,     0.68413,     0.68411,     0.68414,     0.68417,     0.68416,     0.68429,      0.6842,     0.68431,     0.68443,\n",
       "            0.68456,      0.6846,     0.68462,     0.68474,     0.68485,     0.68498,     0.68494,     0.68507,     0.68511,      0.6851,     0.68493,     0.68509,     0.68495,     0.68494,     0.68493,     0.68484,      0.6848,      0.6847,     0.68471,     0.68469,     0.68473,     0.68473,     0.68473,\n",
       "            0.68457,     0.68453,     0.68466,     0.68472,     0.68468,     0.68467,      0.6846,      0.6845,     0.68433,     0.68434,     0.68435,     0.68428,     0.68432,     0.68439,     0.68425,     0.68424,      0.6841,     0.68401,     0.68403,     0.68389,     0.68391,     0.68399,     0.68387,\n",
       "            0.68384,     0.68384,     0.68382,     0.68341,     0.68334,     0.68326,     0.68294,     0.68269,     0.68261,     0.68245,     0.68244,     0.68242,     0.68252,     0.68233,     0.68222,     0.68206,     0.68206,     0.68184,     0.68161,     0.68159,     0.68149,     0.68128,     0.68121,\n",
       "            0.68096,     0.68071,     0.68046,     0.68024,     0.67988,     0.67973,      0.6795,     0.67932,     0.67924,     0.67908,     0.67898,     0.67885,     0.67873,     0.67836,     0.67822,     0.67801,     0.67794,     0.67791,     0.67781,     0.67775,     0.67748,     0.67735,     0.67731,\n",
       "            0.67711,     0.67703,     0.67685,     0.67687,     0.67681,     0.67667,      0.6764,     0.67631,     0.67615,     0.67601,      0.6759,     0.67575,     0.67565,     0.67554,     0.67545,     0.67522,     0.67502,     0.67486,     0.67472,     0.67452,     0.67453,     0.67417,     0.67405,\n",
       "            0.67386,     0.67368,     0.67358,     0.67331,     0.67314,     0.67278,     0.67249,     0.67243,     0.67231,     0.67187,     0.67183,     0.67175,      0.6716,      0.6715,     0.67141,     0.67106,     0.67093,     0.67076,     0.67053,     0.67027,     0.67019,     0.67011,     0.66995,\n",
       "            0.66974,     0.66947,     0.66929,     0.66893,     0.66886,     0.66862,     0.66844,     0.66834,     0.66822,     0.66806,     0.66799,     0.66781,     0.66739,     0.66722,     0.66691,     0.66664,      0.6663,     0.66593,     0.66572,     0.66545,     0.66523,     0.66503,      0.6646,\n",
       "            0.66411,     0.66376,     0.66347,     0.66333,     0.66312,     0.66292,     0.66268,     0.66252,     0.66227,     0.66186,     0.66179,     0.66171,     0.66143,     0.66113,     0.66091,     0.66066,     0.66004,     0.65966,     0.65934,     0.65903,     0.65882,     0.65848,     0.65822,\n",
       "            0.65804,     0.65767,      0.6574,     0.65716,     0.65678,     0.65638,     0.65607,     0.65564,     0.65527,     0.65472,      0.6544,     0.65407,     0.65366,     0.65337,     0.65313,     0.65264,     0.65238,     0.65211,     0.65183,     0.65162,      0.6512,      0.6508,     0.65059,\n",
       "            0.65026,     0.64968,     0.64944,     0.64907,      0.6488,     0.64848,     0.64809,     0.64779,     0.64743,     0.64712,     0.64682,     0.64654,     0.64624,     0.64554,     0.64533,      0.6451,     0.64469,     0.64427,     0.64395,     0.64361,     0.64323,     0.64305,     0.64254,\n",
       "            0.64214,     0.64188,     0.64148,     0.64107,     0.64073,     0.64049,     0.64002,     0.63951,     0.63914,     0.63883,     0.63849,     0.63803,     0.63783,     0.63751,     0.63707,     0.63652,     0.63625,      0.6358,     0.63542,     0.63505,     0.63406,     0.63375,      0.6333,\n",
       "            0.63289,     0.63252,     0.63209,     0.63161,     0.63119,      0.6307,     0.63022,     0.62985,     0.62956,     0.62917,     0.62871,     0.62824,     0.62753,     0.62701,     0.62652,     0.62626,     0.62565,      0.6253,     0.62491,     0.62453,     0.62402,     0.62372,     0.62347,\n",
       "            0.62306,     0.62257,     0.62216,     0.62161,     0.62124,     0.62065,     0.62017,     0.61984,     0.61935,     0.61876,     0.61829,     0.61787,     0.61746,     0.61699,     0.61599,     0.61546,     0.61494,     0.61469,     0.61432,     0.61389,      0.6134,     0.61292,     0.61237,\n",
       "            0.61205,     0.61153,       0.611,     0.61051,     0.61006,     0.60954,       0.609,     0.60845,     0.60806,     0.60769,     0.60741,     0.60692,     0.60642,     0.60585,     0.60534,     0.60484,     0.60447,     0.60395,      0.6035,     0.60286,     0.60251,     0.60175,      0.6014,\n",
       "            0.60092,     0.60056,     0.60003,     0.59939,     0.59888,     0.59803,     0.59766,     0.59689,     0.59636,     0.59582,     0.59536,     0.59473,     0.59431,      0.5939,     0.59322,     0.59237,     0.59193,     0.59138,     0.59073,     0.59038,     0.58978,     0.58914,      0.5887,\n",
       "            0.58806,     0.58756,     0.58689,     0.58645,     0.58594,     0.58477,     0.58409,     0.58392,     0.58315,     0.58268,     0.58214,     0.58171,     0.58103,     0.58033,     0.57966,     0.57901,     0.57836,     0.57779,     0.57723,     0.57654,     0.57612,     0.57486,     0.57402,\n",
       "             0.5733,     0.57235,     0.57166,     0.57107,     0.57038,     0.56981,     0.56907,      0.5686,     0.56799,     0.56624,     0.56624,     0.56495,      0.5649,     0.56374,     0.56369,     0.56225,     0.56215,     0.56111,     0.56102,     0.55993,     0.55986,      0.5583,      0.5573,\n",
       "            0.55722,     0.55586,     0.55578,     0.55486,      0.5548,     0.55335,     0.55327,     0.55192,      0.5518,     0.55033,     0.55022,     0.54865,     0.54732,     0.54721,     0.54601,     0.54593,     0.54449,     0.54441,     0.54282,     0.54177,     0.54172,     0.53991,     0.53988,\n",
       "            0.53832,     0.53827,     0.53707,     0.53701,     0.53531,     0.53364,     0.53363,     0.53256,     0.53248,     0.53101,     0.53098,      0.5297,     0.52965,     0.52839,     0.52704,     0.52699,     0.52579,     0.52574,     0.52427,     0.52278,     0.52264,     0.52143,      0.5214,\n",
       "            0.52024,     0.52019,     0.51873,     0.51735,     0.51727,     0.51599,      0.5159,     0.51513,      0.5151,     0.51384,     0.51224,     0.51218,     0.51058,     0.50845,      0.5084,      0.5066,     0.50652,     0.50499,     0.50488,     0.50346,     0.50155,     0.50149,     0.49961,\n",
       "            0.49959,     0.49768,     0.49763,     0.49548,     0.49379,     0.49369,     0.49194,     0.49186,     0.48973,     0.48793,     0.48583,     0.48575,      0.4839,     0.48382,     0.48157,     0.47969,      0.4796,     0.47771,     0.47767,      0.4758,     0.47435,     0.47429,     0.47248,\n",
       "            0.47244,     0.47043,     0.46869,     0.46862,     0.46684,     0.46685,     0.46462,      0.4629,     0.46034,     0.46024,      0.4576,     0.45751,     0.45541,     0.45325,     0.45323,     0.45103,     0.44864,     0.44842,     0.44585,     0.44374,      0.4437,     0.44169,     0.44165,\n",
       "            0.43935,     0.43723,     0.43716,     0.43487,      0.4326,     0.43049,     0.43038,      0.4285,     0.42647,      0.4263,     0.42391,     0.42186,     0.42173,     0.41944,     0.41661,     0.41648,     0.41319,     0.41038,     0.41024,     0.40772,     0.40485,     0.40472,     0.40213,\n",
       "            0.39909,     0.39611,     0.39587,     0.39292,     0.39014,     0.38762,      0.3876,     0.38454,     0.38113,     0.38109,     0.37807,     0.37575,     0.37573,     0.37278,     0.36998,     0.36704,     0.36702,     0.36361,     0.36015,     0.36012,     0.35648,     0.35293,     0.34971,\n",
       "            0.34597,     0.34592,     0.34247,     0.33859,     0.33532,     0.33527,     0.33167,     0.32809,     0.32408,     0.32406,     0.32034,     0.31686,     0.31331,     0.31327,     0.30889,     0.30472,      0.3008,     0.29734,      0.2933,     0.28955,     0.28951,     0.28496,     0.28106,\n",
       "            0.27663,     0.27277,     0.27273,     0.26854,     0.26404,     0.25895,     0.25387,     0.25384,      0.2483,     0.24413,     0.23915,     0.23394,     0.22949,     0.22946,     0.22499,     0.21606,     0.21603,     0.21077,     0.20616,     0.20091,     0.19573,     0.19125,     0.18639,\n",
       "            0.18636,     0.18105,     0.17599,      0.1722,     0.16711,     0.16231,     0.15785,     0.15277,     0.14744,     0.14254,     0.14248,      0.1386,     0.12833,     0.12342,      0.1188,     0.11446,     0.11033,      0.1061,     0.10595,     0.10068,    0.097368,    0.093516,    0.090453,\n",
       "           0.086908,    0.084037,    0.080523,    0.077034,    0.073387,    0.070205,     0.06729,      0.0638,    0.060628,    0.056117,    0.053254,    0.050814,    0.048896,    0.046253,    0.044277,    0.042394,    0.040749,    0.037318,    0.036043,    0.034679,    0.033167,    0.031263,    0.029836,\n",
       "           0.028324,    0.026999,    0.024738,    0.023211,    0.021928,    0.020495,    0.018467,    0.017475,    0.016631,    0.015736,    0.014046,    0.013497,    0.012848,    0.012348,      0.0112,      0.0105,   0.0098991,   0.0087986,   0.0083965,   0.0079442,   0.0076354,   0.0069589,   0.0066363,\n",
       "           0.005805,   0.0052289,   0.0050759,    0.004498,   0.0041205,   0.0038647,   0.0033651,    0.003207,   0.0027096,   0.0023478,   0.0022296,   0.0019406,   0.0017997,   0.0016841,   0.0013444,   0.0012929,   0.0011231,   0.0010639,  0.00076574,  0.00073223,  0.00070642,  0.00055678,   0.0004702,\n",
       "         0.00035146,  0.00030177,  0.00029144,  0.00028112,  0.00027079,  0.00026046,   0.0001957,  0.00016127,  9.0351e-05,  7.5597e-05,  6.0842e-05,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.11516,     0.11516,     0.14534,     0.16722,     0.18541,     0.20112,     0.21524,     0.22736,      0.2392,     0.25011,     0.26043,     0.26962,     0.27877,      0.2871,     0.29575,     0.30382,     0.31164,     0.31931,     0.32664,      0.3342,     0.34118,     0.34769,     0.35418,\n",
       "            0.36079,     0.36702,     0.37306,     0.37896,     0.38442,     0.38976,     0.39531,     0.40099,     0.40654,     0.41144,     0.41647,     0.42135,      0.4265,      0.4314,     0.43579,     0.44077,     0.44452,     0.44926,     0.45385,     0.45787,     0.46298,     0.46699,     0.47138,\n",
       "            0.47565,     0.47934,     0.48342,     0.48776,     0.49111,      0.4947,     0.49887,     0.50223,     0.50615,     0.50987,     0.51341,     0.51654,     0.52004,     0.52433,     0.52738,     0.53094,     0.53421,     0.53837,     0.54141,     0.54433,     0.54743,     0.55044,     0.55488,\n",
       "            0.55773,     0.56088,      0.5641,     0.56636,     0.56956,     0.57246,     0.57553,     0.57794,     0.58114,     0.58441,     0.58691,      0.5903,     0.59272,     0.59521,     0.59898,     0.60138,     0.60494,      0.6075,     0.61009,     0.61242,     0.61489,     0.61817,     0.62077,\n",
       "            0.62311,     0.62557,     0.62803,     0.63029,     0.63258,     0.63525,     0.63746,     0.63908,     0.64178,     0.64428,     0.64671,     0.64882,     0.65038,     0.65314,     0.65544,     0.65772,     0.65965,     0.66197,     0.66457,     0.66588,     0.66824,     0.66989,     0.67261,\n",
       "            0.67413,     0.67655,     0.67795,     0.68054,     0.68197,     0.68444,     0.68604,     0.68787,     0.69018,      0.6916,     0.69459,     0.69588,     0.69772,     0.70003,     0.70157,     0.70302,     0.70466,     0.70648,     0.70796,     0.70956,     0.71097,     0.71341,     0.71516,\n",
       "            0.71663,     0.71796,      0.7193,     0.72104,     0.72233,     0.72342,     0.72482,     0.72739,     0.72882,     0.73063,     0.73203,      0.7335,     0.73515,     0.73675,     0.73828,     0.73967,     0.74111,     0.74232,     0.74374,     0.74545,     0.74613,     0.74755,     0.74902,\n",
       "            0.75022,     0.75193,     0.75351,     0.75517,     0.75678,     0.75833,     0.75902,      0.7603,     0.76186,     0.76336,      0.7648,     0.76621,      0.7674,     0.76848,     0.77011,     0.77175,     0.77247,     0.77398,     0.77533,     0.77669,     0.77714,     0.77842,     0.77976,\n",
       "            0.78082,     0.78199,     0.78323,     0.78474,     0.78511,     0.78662,     0.78799,     0.78886,     0.79015,     0.79137,     0.79196,     0.79368,     0.79537,     0.79613,     0.79785,     0.79856,     0.79955,      0.8007,     0.80137,     0.80241,      0.8029,     0.80402,     0.80485,\n",
       "            0.80661,     0.80778,     0.80844,     0.81018,     0.81081,     0.81231,     0.81311,     0.81438,     0.81497,     0.81643,     0.81678,     0.81795,     0.81842,     0.81967,     0.82028,     0.82146,       0.822,     0.82308,     0.82366,     0.82473,     0.82527,     0.82675,     0.82735,\n",
       "             0.8288,     0.82961,     0.83042,     0.83158,     0.83236,     0.83359,     0.83422,     0.83551,      0.8364,     0.83702,     0.83793,     0.83874,     0.83959,     0.84006,     0.84058,     0.84155,     0.84194,     0.84229,     0.84362,     0.84417,     0.84514,     0.84558,     0.84628,\n",
       "            0.84711,     0.84773,     0.84862,     0.84983,      0.8503,     0.85079,     0.85197,     0.85257,     0.85349,     0.85396,     0.85462,     0.85517,     0.85667,      0.8573,     0.85774,     0.85899,     0.85947,     0.85986,     0.86116,      0.8616,     0.86215,     0.86284,     0.86379,\n",
       "            0.86445,     0.86511,     0.86564,     0.86643,     0.86701,     0.86765,     0.86866,     0.86906,     0.86954,     0.86994,     0.87095,     0.87142,     0.87212,     0.87271,     0.87389,     0.87427,     0.87474,     0.87524,     0.87621,     0.87691,     0.87734,     0.87754,     0.87815,\n",
       "            0.87927,     0.87959,     0.88024,     0.88062,      0.8815,     0.88169,     0.88216,     0.88265,     0.88319,     0.88405,     0.88458,     0.88527,     0.88574,     0.88644,     0.88688,     0.88728,     0.88766,     0.88816,     0.88865,     0.88914,     0.89015,     0.89073,     0.89143,\n",
       "            0.89201,     0.89262,     0.89384,     0.89432,     0.89492,     0.89553,     0.89599,     0.89658,     0.89739,     0.89775,     0.89802,     0.89839,     0.89901,     0.89938,      0.8999,     0.90071,     0.90107,     0.90145,     0.90198,     0.90233,      0.9028,     0.90396,     0.90437,\n",
       "            0.90463,     0.90504,     0.90539,     0.90564,     0.90609,     0.90683,     0.90722,     0.90787,     0.90837,     0.90861,     0.90896,     0.90954,     0.90994,     0.91048,     0.91057,      0.9116,      0.9121,     0.91244,     0.91253,     0.91298,     0.91344,     0.91395,     0.91445,\n",
       "            0.91465,     0.91505,     0.91583,     0.91623,     0.91687,     0.91745,     0.91789,     0.91858,     0.91891,     0.91923,     0.91969,     0.92009,     0.92091,     0.92125,     0.92155,     0.92194,     0.92211,      0.9224,     0.92304,     0.92359,     0.92398,     0.92447,     0.92537,\n",
       "            0.92565,     0.92588,     0.92639,     0.92681,     0.92706,     0.92736,     0.92774,     0.92804,     0.92839,      0.9287,     0.92926,     0.92977,     0.93013,     0.93079,     0.93105,      0.9315,     0.93241,     0.93269,     0.93305,     0.93334,     0.93394,     0.93418,     0.93456,\n",
       "            0.93479,     0.93531,      0.9355,     0.93591,     0.93634,     0.93653,     0.93684,     0.93707,     0.93737,     0.93794,     0.93815,     0.93844,     0.93886,     0.93918,     0.93952,     0.93955,     0.94004,     0.94056,      0.9408,     0.94099,     0.94135,     0.94165,     0.94198,\n",
       "            0.94227,     0.94234,     0.94252,     0.94292,     0.94329,     0.94351,      0.9436,     0.94418,     0.94449,     0.94476,     0.94526,     0.94563,     0.94587,     0.94632,     0.94675,     0.94695,      0.9473,     0.94757,     0.94798,     0.94835,     0.94849,     0.94879,      0.9493,\n",
       "            0.94965,      0.9501,     0.95038,     0.95058,     0.95082,     0.95093,     0.95105,     0.95134,     0.95158,     0.95209,     0.95225,     0.95239,     0.95278,     0.95303,     0.95336,     0.95349,     0.95383,     0.95412,     0.95432,     0.95466,     0.95527,     0.95552,     0.95581,\n",
       "            0.95592,     0.95626,     0.95637,     0.95642,     0.95661,     0.95685,     0.95705,     0.95731,     0.95766,     0.95796,     0.95826,     0.95841,      0.9588,     0.95917,     0.95929,     0.95964,     0.95998,     0.96029,      0.9605,     0.96076,     0.96099,     0.96119,     0.96144,\n",
       "            0.96171,     0.96208,     0.96229,     0.96235,     0.96245,     0.96262,     0.96288,      0.9634,     0.96361,     0.96382,     0.96413,     0.96456,     0.96483,     0.96494,     0.96563,     0.96579,     0.96601,     0.96615,     0.96632,      0.9666,     0.96708,     0.96741,     0.96762,\n",
       "            0.96775,     0.96799,     0.96809,     0.96821,      0.9686,     0.96882,     0.96917,     0.96953,     0.96961,     0.96988,     0.97012,     0.97038,     0.97051,     0.97073,     0.97118,     0.97123,     0.97149,     0.97167,     0.97181,     0.97218,     0.97244,     0.97261,     0.97291,\n",
       "             0.9732,     0.97357,     0.97381,     0.97388,     0.97401,     0.97429,     0.97437,     0.97471,     0.97496,     0.97531,     0.97565,     0.97584,       0.976,     0.97618,     0.97633,     0.97645,     0.97648,     0.97668,     0.97664,     0.97674,     0.97704,     0.97734,     0.97789,\n",
       "            0.97802,     0.97828,     0.97853,     0.97885,     0.97906,     0.97929,     0.97937,     0.97968,     0.97982,     0.98005,     0.98008,     0.98051,     0.98061,      0.9807,     0.98078,     0.98104,     0.98119,     0.98122,     0.98149,     0.98158,     0.98174,     0.98198,     0.98206,\n",
       "            0.98215,     0.98223,      0.9822,      0.9823,     0.98227,     0.98236,     0.98251,     0.98261,     0.98293,     0.98331,     0.98336,     0.98362,     0.98362,     0.98388,     0.98387,     0.98406,     0.98406,     0.98445,     0.98445,     0.98459,     0.98465,     0.98491,     0.98512,\n",
       "            0.98512,     0.98557,     0.98557,     0.98585,     0.98585,     0.98592,     0.98592,     0.98613,     0.98619,     0.98633,     0.98632,     0.98668,       0.987,     0.98699,     0.98741,     0.98741,     0.98756,     0.98755,     0.98757,       0.988,     0.98799,      0.9882,      0.9882,\n",
       "            0.98849,     0.98855,     0.98872,     0.98872,       0.989,     0.98922,     0.98922,      0.9896,      0.9896,     0.98976,     0.98976,     0.98986,     0.98992,     0.99017,     0.99034,     0.99034,     0.99052,     0.99052,     0.99062,     0.99093,     0.99093,     0.99125,     0.99125,\n",
       "             0.9915,     0.99155,     0.99168,     0.99214,     0.99214,     0.99212,     0.99211,     0.99238,     0.99238,     0.99264,     0.99283,     0.99283,     0.99287,     0.99312,     0.99312,      0.9933,      0.9933,     0.99327,     0.99327,     0.99339,     0.99373,     0.99373,     0.99377,\n",
       "            0.99377,     0.99387,     0.99389,     0.99408,      0.9942,      0.9942,      0.9944,      0.9944,     0.99445,      0.9945,     0.99462,     0.99462,     0.99483,     0.99483,     0.99479,       0.995,       0.995,     0.99498,     0.99498,     0.99495,     0.99517,     0.99517,     0.99531,\n",
       "             0.9953,     0.99544,      0.9955,      0.9955,     0.99552,     0.99556,     0.99586,     0.99617,     0.99623,     0.99623,      0.9962,      0.9962,     0.99626,     0.99632,     0.99632,     0.99647,     0.99644,     0.99644,      0.9965,     0.99657,     0.99657,     0.99664,     0.99664,\n",
       "             0.9967,     0.99677,     0.99677,     0.99702,     0.99709,     0.99735,     0.99734,     0.99742,      0.9975,      0.9975,     0.99767,     0.99774,     0.99774,     0.99782,      0.9978,      0.9978,     0.99788,     0.99786,     0.99786,     0.99784,     0.99792,     0.99792,      0.9979,\n",
       "            0.99788,     0.99786,     0.99786,     0.99784,     0.99793,     0.99791,     0.99791,     0.99799,     0.99808,     0.99808,     0.99827,     0.99826,     0.99826,     0.99835,     0.99834,     0.99843,     0.99843,     0.99853,     0.99863,     0.99863,     0.99896,     0.99894,     0.99905,\n",
       "            0.99904,     0.99904,     0.99903,     0.99901,       0.999,       0.999,     0.99899,     0.99897,     0.99896,     0.99896,     0.99894,     0.99893,     0.99892,     0.99892,      0.9989,     0.99888,     0.99886,     0.99885,     0.99898,     0.99896,     0.99896,     0.99894,     0.99908,\n",
       "            0.99906,      0.9992,      0.9992,     0.99935,     0.99934,     0.99932,     0.99948,     0.99948,     0.99947,     0.99946,     0.99944,     0.99943,     0.99942,     0.99942,      0.9994,     0.99938,     0.99938,     0.99936,     0.99934,     0.99932,      0.9993,     0.99929,     0.99927,\n",
       "            0.99927,     0.99924,     0.99922,      0.9992,     0.99917,     0.99915,     0.99912,     0.99909,     0.99905,     0.99902,     0.99902,     0.99932,     0.99927,     0.99923,      0.9992,     0.99917,     0.99914,      0.9991,      0.9991,     0.99905,     0.99902,     0.99897,     0.99894,\n",
       "            0.99889,     0.99943,      0.9994,     0.99937,     0.99934,     0.99931,     0.99928,     0.99924,     0.99919,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.7137,      0.7137,     0.71118,     0.70916,     0.70758,     0.70566,     0.70438,     0.70292,     0.70158,     0.70057,     0.69939,     0.69828,     0.69738,      0.6964,     0.69501,     0.69402,     0.69312,     0.69176,      0.6907,     0.69004,     0.68929,     0.68861,      0.6876,\n",
       "            0.68685,     0.68584,     0.68528,     0.68458,     0.68365,     0.68274,     0.68206,     0.68138,     0.68067,     0.67987,     0.67921,     0.67846,     0.67752,     0.67667,     0.67591,     0.67503,     0.67432,      0.6737,     0.67254,     0.67176,     0.67125,      0.6706,     0.67014,\n",
       "            0.66944,     0.66891,     0.66835,      0.6679,     0.66717,     0.66654,     0.66589,     0.66531,     0.66476,       0.664,     0.66332,     0.66279,     0.66221,      0.6615,     0.66102,     0.66042,     0.65997,     0.65934,     0.65868,     0.65821,      0.6578,     0.65722,     0.65666,\n",
       "            0.65591,     0.65563,     0.65533,     0.65493,     0.65425,     0.65354,     0.65294,     0.65249,     0.65201,     0.65158,     0.65124,     0.65064,     0.65029,     0.64961,     0.64891,     0.64853,     0.64782,     0.64732,     0.64661,     0.64609,     0.64556,     0.64495,      0.6444,\n",
       "            0.64397,     0.64347,     0.64289,     0.64243,     0.64207,      0.6415,     0.64097,     0.64072,     0.64029,     0.63976,     0.63938,     0.63868,     0.63823,     0.63778,     0.63727,     0.63679,     0.63649,     0.63593,     0.63525,     0.63475,     0.63414,     0.63392,     0.63346,\n",
       "            0.63304,     0.63233,     0.63213,      0.6313,     0.63069,     0.63009,     0.62974,     0.62951,     0.62883,      0.6285,      0.6281,      0.6277,     0.62724,     0.62651,     0.62601,     0.62571,      0.6254,      0.6246,     0.62409,      0.6237,     0.62341,     0.62288,     0.62238,\n",
       "            0.62195,     0.62166,     0.62117,     0.62074,     0.62029,     0.61964,     0.61916,     0.61873,     0.61827,      0.6179,     0.61729,     0.61679,     0.61638,      0.6156,     0.61515,     0.61462,     0.61419,     0.61373,     0.61326,     0.61298,     0.61268,      0.6122,     0.61175,\n",
       "            0.61132,     0.61104,     0.61041,     0.61016,     0.60958,     0.60898,     0.60868,     0.60823,     0.60779,     0.60749,     0.60704,     0.60641,     0.60623,     0.60583,      0.6052,     0.60485,     0.60477,     0.60414,     0.60358,     0.60306,     0.60273,     0.60231,     0.60182,\n",
       "            0.60175,     0.60129,     0.60079,     0.60024,     0.60004,     0.59971,      0.5993,     0.59908,     0.59861,     0.59807,     0.59767,     0.59711,     0.59678,     0.59656,     0.59613,     0.59581,     0.59543,      0.5948,     0.59459,     0.59406,     0.59376,     0.59308,     0.59286,\n",
       "            0.59249,       0.592,     0.59163,     0.59104,     0.59069,     0.59034,     0.59011,     0.58938,     0.58906,     0.58862,     0.58837,     0.58776,     0.58759,     0.58691,     0.58674,      0.5861,     0.58588,     0.58537,     0.58507,     0.58472,     0.58432,     0.58374,     0.58361,\n",
       "            0.58308,     0.58274,     0.58238,     0.58197,     0.58175,     0.58134,     0.58098,     0.58054,     0.58016,     0.57986,     0.57918,     0.57903,     0.57842,     0.57817,     0.57792,     0.57733,     0.57709,     0.57679,     0.57618,      0.5759,      0.5755,      0.5753,     0.57498,\n",
       "            0.57437,     0.57403,     0.57379,     0.57333,     0.57307,     0.57283,      0.5722,     0.57178,     0.57114,     0.57094,     0.57066,     0.57031,      0.5697,     0.56951,     0.56913,     0.56857,     0.56817,     0.56787,     0.56734,     0.56695,     0.56674,     0.56656,     0.56598,\n",
       "            0.56566,     0.56537,     0.56512,     0.56423,     0.56389,     0.56351,     0.56265,     0.56214,     0.56183,     0.56145,     0.56101,     0.56079,     0.56064,     0.56013,      0.5595,     0.55914,     0.55895,     0.55845,     0.55774,     0.55743,     0.55712,     0.55676,     0.55643,\n",
       "            0.55565,     0.55518,     0.55459,     0.55414,     0.55333,     0.55304,     0.55256,     0.55213,     0.55182,     0.55126,     0.55094,      0.5505,     0.55016,      0.5494,     0.54904,     0.54862,     0.54838,     0.54815,     0.54784,     0.54756,     0.54683,     0.54644,     0.54613,\n",
       "            0.54565,     0.54532,     0.54464,     0.54448,     0.54419,     0.54377,     0.54325,     0.54293,     0.54242,     0.54211,     0.54187,     0.54154,     0.54119,     0.54091,     0.54061,     0.54002,     0.53964,      0.5393,     0.53893,     0.53855,      0.5384,     0.53753,     0.53723,\n",
       "             0.5369,     0.53653,     0.53628,     0.53585,     0.53548,     0.53476,     0.53426,     0.53396,     0.53363,     0.53299,     0.53282,     0.53252,      0.5322,     0.53189,     0.53174,     0.53096,     0.53063,      0.5303,     0.52998,      0.5295,     0.52926,     0.52898,     0.52862,\n",
       "            0.52829,     0.52781,     0.52733,     0.52675,     0.52645,     0.52597,     0.52559,     0.52525,       0.525,     0.52469,     0.52446,     0.52411,     0.52333,       0.523,     0.52252,     0.52207,     0.52161,     0.52105,     0.52059,     0.52009,      0.5197,      0.5193,     0.51849,\n",
       "            0.51781,     0.51731,      0.5168,      0.5165,     0.51616,     0.51584,     0.51542,     0.51514,     0.51472,     0.51414,     0.51389,     0.51363,     0.51318,     0.51262,     0.51227,     0.51184,     0.51083,     0.51028,     0.50979,     0.50934,     0.50891,     0.50843,       0.508,\n",
       "            0.50772,     0.50713,     0.50676,     0.50635,     0.50578,     0.50524,     0.50479,     0.50421,     0.50368,     0.50287,     0.50244,     0.50196,     0.50136,     0.50093,     0.50055,     0.49997,     0.49952,     0.49906,     0.49866,     0.49836,     0.49777,     0.49722,     0.49688,\n",
       "            0.49642,     0.49572,     0.49539,     0.49486,     0.49444,     0.49401,     0.49353,     0.49302,     0.49252,     0.49209,     0.49161,     0.49118,     0.49078,     0.48985,      0.4895,     0.48917,     0.48861,     0.48806,     0.48757,     0.48709,     0.48661,     0.48633,     0.48562,\n",
       "            0.48507,     0.48466,     0.48413,     0.48361,     0.48316,     0.48285,     0.48229,     0.48164,     0.48116,     0.48068,     0.48026,      0.4797,     0.47937,     0.47894,     0.47836,     0.47771,     0.47733,     0.47675,     0.47627,     0.47577,     0.47451,      0.4741,     0.47352,\n",
       "            0.47304,     0.47254,     0.47204,     0.47148,     0.47097,     0.47037,     0.46979,     0.46932,     0.46891,      0.4684,     0.46782,     0.46727,     0.46639,     0.46573,     0.46516,      0.4648,     0.46404,     0.46359,     0.46311,     0.46263,     0.46201,     0.46164,     0.46131,\n",
       "             0.4608,     0.46018,     0.45968,     0.45907,     0.45864,     0.45796,     0.45738,      0.4569,     0.45632,     0.45564,     0.45506,     0.45451,       0.454,     0.45347,     0.45224,     0.45163,     0.45103,     0.45073,     0.45029,     0.44977,     0.44914,     0.44856,     0.44792,\n",
       "            0.44755,     0.44695,     0.44636,     0.44581,     0.44525,     0.44465,       0.444,     0.44333,     0.44291,     0.44246,     0.44211,     0.44154,     0.44099,     0.44033,      0.4397,     0.43916,     0.43872,     0.43814,     0.43763,      0.4369,     0.43647,     0.43564,     0.43521,\n",
       "            0.43465,      0.4342,      0.4336,     0.43292,     0.43236,     0.43142,     0.43101,     0.43016,     0.42955,     0.42892,     0.42838,      0.4277,     0.42723,     0.42677,     0.42605,     0.42514,     0.42468,     0.42408,     0.42342,     0.42305,     0.42236,     0.42166,      0.4211,\n",
       "            0.42042,     0.41987,     0.41914,     0.41863,     0.41808,     0.41684,     0.41614,     0.41591,      0.4151,     0.41459,     0.41403,     0.41352,     0.41282,     0.41209,     0.41141,      0.4107,     0.41002,     0.40944,     0.40884,     0.40813,     0.40768,     0.40638,     0.40552,\n",
       "            0.40479,     0.40383,     0.40315,     0.40255,     0.40187,     0.40129,     0.40053,     0.40005,     0.39939,      0.3976,     0.39759,     0.39628,     0.39623,     0.39505,     0.39499,     0.39356,     0.39346,     0.39237,     0.39229,      0.3912,     0.39112,     0.38956,     0.38855,\n",
       "            0.38848,     0.38709,     0.38701,     0.38608,     0.38602,     0.38461,     0.38453,     0.38319,     0.38307,     0.38163,     0.38153,     0.37996,     0.37864,     0.37854,     0.37733,     0.37726,     0.37586,     0.37578,     0.37427,     0.37321,     0.37316,     0.37142,     0.37139,\n",
       "            0.36987,     0.36982,     0.36866,     0.36861,     0.36697,     0.36537,     0.36536,     0.36431,     0.36424,     0.36284,     0.36281,      0.3616,     0.36155,     0.36034,     0.35907,     0.35902,     0.35788,     0.35783,     0.35646,     0.35505,     0.35492,     0.35376,     0.35373,\n",
       "            0.35264,     0.35258,     0.35123,      0.3499,     0.34983,     0.34867,     0.34858,     0.34785,     0.34782,     0.34664,     0.34516,     0.34511,     0.34365,      0.3417,     0.34165,     0.34001,     0.33993,     0.33856,     0.33846,     0.33717,     0.33542,     0.33537,     0.33368,\n",
       "            0.33366,     0.33195,      0.3319,     0.32997,     0.32846,     0.32838,     0.32681,     0.32673,     0.32486,     0.32327,     0.32142,     0.32134,      0.3197,     0.31964,     0.31767,     0.31602,     0.31595,      0.3143,     0.31427,     0.31266,     0.31138,     0.31133,     0.30976,\n",
       "            0.30973,     0.30799,     0.30649,     0.30643,     0.30492,     0.30492,     0.30299,      0.3015,     0.29932,     0.29925,     0.29702,     0.29694,     0.29516,     0.29335,     0.29333,     0.29148,     0.28949,     0.28931,     0.28716,     0.28541,     0.28538,     0.28371,     0.28368,\n",
       "            0.28178,     0.28003,     0.27998,     0.27808,     0.27622,     0.27448,      0.2744,     0.27286,     0.27121,     0.27108,     0.26913,     0.26748,     0.26737,     0.26552,     0.26327,     0.26316,     0.26053,      0.2583,     0.25819,      0.2562,     0.25393,     0.25383,      0.2518,\n",
       "            0.24942,      0.2471,     0.24691,     0.24462,     0.24247,     0.24053,     0.24051,     0.23815,     0.23554,      0.2355,     0.23319,     0.23143,     0.23141,     0.22918,     0.22707,     0.22485,     0.22484,     0.22227,     0.21969,     0.21967,     0.21695,     0.21433,     0.21195,\n",
       "            0.20921,     0.20917,     0.20666,     0.20384,     0.20147,     0.20144,     0.19884,     0.19627,     0.19342,      0.1934,     0.19075,     0.18829,     0.18579,     0.18576,     0.18269,     0.17978,     0.17706,     0.17467,     0.17188,     0.16931,     0.16928,     0.16618,     0.16353,\n",
       "            0.16054,     0.15795,     0.15792,     0.15511,     0.15211,     0.14875,      0.1454,     0.14538,     0.14176,     0.13905,     0.13582,     0.13247,     0.12963,     0.12961,     0.12676,     0.12112,      0.1211,     0.11781,     0.11493,     0.11168,     0.10849,     0.10575,     0.10278,\n",
       "            0.10276,    0.099544,    0.096495,    0.094221,    0.091179,    0.088329,    0.085692,    0.082709,    0.079594,    0.076747,    0.076709,    0.074466,     0.06857,    0.065773,    0.063153,    0.060709,    0.058388,    0.056022,    0.055942,     0.05301,    0.051178,    0.049054,    0.047371,\n",
       "            0.04543,    0.043863,    0.041952,    0.040061,    0.038092,     0.03638,    0.034817,    0.032952,    0.031263,    0.028868,    0.027356,     0.02607,    0.025061,    0.023674,     0.02264,    0.021656,    0.020798,    0.019014,    0.018352,    0.017646,    0.016863,     0.01588,    0.015144,\n",
       "           0.014366,    0.013684,    0.012524,    0.011742,    0.011086,    0.010354,   0.0093197,   0.0088146,   0.0083851,   0.0079304,   0.0070726,   0.0067943,   0.0064655,   0.0062124,   0.0056317,   0.0052777,   0.0049742,   0.0044187,   0.0042159,   0.0039879,   0.0038323,   0.0034916,   0.0033292,\n",
       "          0.0029109,   0.0026213,   0.0025444,   0.0022541,   0.0020645,   0.0019361,   0.0016854,   0.0016061,   0.0013566,   0.0011753,    0.001116,  0.00097125,  0.00090065,  0.00084277,  0.00067267,  0.00064685,  0.00056188,  0.00053222,  0.00038302,  0.00036625,  0.00035334,  0.00027847,  0.00023515,\n",
       "         0.00017576,  0.00015091,  0.00014574,  0.00014058,  0.00013541,  0.00013025,  9.7857e-05,  8.0643e-05,  4.5177e-05,    3.78e-05,  3.0422e-05,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.3909056061570317)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.3611])\n",
       "names: {0: 'face'}\n",
       "nt_per_class: array([39696])\n",
       "nt_per_image: array([3222])\n",
       "results_dict: {'metrics/precision(B)': np.float64(0.8415515108797327), 'metrics/recall(B)': np.float64(0.5773333625174281), 'metrics/mAP50(B)': np.float64(0.6591643314766327), 'metrics/mAP50-95(B)': np.float64(0.36109908112152045), 'fitness': np.float64(0.3909056061570317)}\n",
       "save_dir: PosixPath('runs/detect/yolov8-face')\n",
       "speed: {'preprocess': 0.12944119533359938, 'inference': 1.0084922641012106, 'loss': 0.00021137632109150892, 'postprocess': 0.7374098846199244}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained YOLOv8n model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Freeze all layers\n",
    "for name, param in model.model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last 10 layers\n",
    "# This includes detection heads and some backbone layers\n",
    "unfreeze_count = 10\n",
    "for name, param in list(model.model.named_parameters())[-unfreeze_count:]:\n",
    "    param.requires_grad = True\n",
    "    print(f\"[Unfrozen] {name}\")\n",
    "\n",
    "# Train with partial fine-tuning\n",
    "model.train(\n",
    "    data=\"wider_face_yolo/data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"yolov8-face\",\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e8e34",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7cfb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/person.jpg: 480x640 24 faces, 20.7ms\n",
      "Speed: 1.7ms preprocess, 20.7ms inference, 92.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'face'}\n",
       " obb: None\n",
       " orig_img: array([[[160, 154, 155],\n",
       "         [160, 154, 155],\n",
       "         [161, 155, 156],\n",
       "         ...,\n",
       "         [143, 136, 139],\n",
       "         [143, 136, 139],\n",
       "         [143, 136, 139]],\n",
       " \n",
       "        [[160, 154, 155],\n",
       "         [161, 155, 156],\n",
       "         [162, 156, 157],\n",
       "         ...,\n",
       "         [143, 136, 139],\n",
       "         [143, 136, 139],\n",
       "         [143, 136, 139]],\n",
       " \n",
       "        [[162, 156, 157],\n",
       "         [162, 156, 157],\n",
       "         [163, 157, 158],\n",
       "         ...,\n",
       "         [144, 137, 140],\n",
       "         [144, 137, 140],\n",
       "         [144, 137, 140]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       " \n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       " \n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]]], dtype=uint8)\n",
       " orig_shape: (956, 1300)\n",
       " path: '/mnt/A04C91DC4C91AE12/Israil/work/DL/Object_Detection/Assignment-7/bbbbbb/person.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict3'\n",
       " speed: {'preprocess': 1.658114000747446, 'inference': 20.73253900016425, 'postprocess': 92.25437200075248}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load best model after training\n",
    "model = YOLO(\"runs/detect/yolov8-face/weights/best.pt\")\n",
    "\n",
    "# Predict on image\n",
    "model.predict(source=\"person.jpg\", save=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
